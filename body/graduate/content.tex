\chapter{绪论}
\section{背景与意义}

随着科技的进步，机器人技术近年来实现了飞速发展，其应用场景已从传统的工业制造领域，
迅速拓展至医疗、教育、军事、交通等更广阔的社会服务与民生领域。机器人技术已成为驱动
未来新兴产业发展和科技创新的关键基础，对促进国民经济增长和加强国防建设具有不可替代
的战略意义\cite{2013RobotProgress}。移动与操作是机器人需要实现的两个功能。
在各种机器人构型中，腿足式机器人因其仿生学设计，展现出卓越的环境适应性和通过能力，
能够灵活跨越障碍、稳定通过复杂路面，使其成为探险、搜救和野外作业等领域不可或缺的
理想平台\cite{孟健2015复杂地形环境四足机器人运动控制方法研究与实现}。但是在现实中，
许多任务涉及操作任务，尽管腿足式机器人可以使用腿足完成推、拉等简单的
操作任务，这种方式通常会削弱机器人的移动能力，且难以在运动过程中进行精细化的操作。
为四足机器人装配机械臂（Legged Manipulator System，简称LMS）成为了增强其作业能力的关键途径。
机械臂的加入使得四足机器人从单纯的移动平台升级为了具备操作能力的多功能系统，能够执行远远
操作仅仅使用腿足作为执行器的复杂精细的多样化任务。
例如，在电力、油气等基础设施的巡检任务中，足式机械臂可以行走在复杂的管道或崎岖地面上，
并利用机械臂搭载传感器或工具进行高精度仪表读数、阀门开关甚至简单故障的现场维修。
在生活服务与辅助照护领域，足式机械臂能够稳定的跨过家庭环境中的地毯、门槛与楼梯场景，并
利用机械臂完成拿快递、开门与打扫房间等任务。
% 在地震废墟、核泄漏场所或有毒气体环境中，履带和轮式机器人往往寸步难行，而足式机械臂
% 可以在碎石瓦砾上行走并利用机械臂移除障碍物、打开紧闭的门、递送急救物资，甚至进行
% 生命探测仪器的精确部署。它们能够深入危险地带执行传统机器人无法完成的“侦查-清理-救援”
% 一体化复杂任务，极大地提高了救援效率和安全性。

然而，四足机械臂控制系统是一个高自由度、强耦合和高度非线性的动态系统，关于该构型的全身
目标规划与全身协同控制仍然是当前研究中的关键难点。尤其在全身协同控制层面，机械臂的运动会对四足机器人
稳定性会造成显著的扰动；同时，四足机器人还必须主动的进行步态调整与位姿配合，以扩展机械臂的操作空间，
确保操作任务的成功执行。如果高效的解决这种多目标、强耦合的全身动态协调控制问题，是制约足式机械臂
从理论走向实际应用的关键瓶颈。
目前，模型预测控制（Model Predictive Control，简称MPC）是实现足式机械臂精确控制的主流方法。
不过其控制方法存在显著的局限性：首先，它必须依赖于精确且复杂的全身动力学模型，这给建模过程带来了巨大
的工程难度和不确定性；其次，MPC的计算复杂度高，难以在高度动态和实时环境（如复杂地形）中满足高频率
的控制需求；此外，在机械臂末端执行器进行复杂操作时，还需要耗费巨大的工程努力来处理和避免奇异点等问题，
以确保控制的稳定性和精度。
相比之下，近年来，深度强化学习（Deep Reinforcement Learning, 简称DRL）在机器人控制领域，
尤其是四足机器人运动控制方面，展现出强大的鲁棒性与环境适应性
\cite{gu2017deep, kalashnikov2018scalable, chen2023visual, kim2024not, nahrendra2023dreamwaq}。
DRL通过结合深度神经网络的强大拟合能力和强化学习的决策优化能力，使智能体通过与环境的大规模
并行化仿真交互，自主学习并优化控制策略。这种基于数据驱动的控制范式，显著减少了对精确物理建模的依赖，
提供了一种更加灵活、高效且鲁棒的全身控制解决方案。因此，深入研究基于深度强化学习的
四足机械臂全身运动协同控制方法，对于推动该平台在复杂任务场景中的智能化和自动化应用具有
重大的理论与实际意义。

综上所述，如何利用深度强化学习算法实现足式机械臂流畅且鲁棒的全身协同控制是本文的核心研究目标。
足式机械臂的全身协同控制问题可以被抽象为两个相互耦合的控制任务：
一是四足机器人的速度追踪运动控制；二是机械臂末端执行器的位姿追踪控制。
这两个任务是相互制约、紧密耦合的。具体而言，基座的动态运动会对机械臂的位姿跟踪
产生扰动，而机械臂的运动反过来也会对基座的稳定造成挑战。更重要的是，
为了让机械臂能够到达并稳定操作给定的目标位姿，基座必须流畅地做出主动配合行为
（如俯仰、侧倾），而这种配合行为的设计难度极高，且会对两个控制目标造成进一步的耦合影响。
针对上述挑战，本文提出一种基于深度强化学习的足式机械臂全身协同控制方法。
具体而言，我们利用机械臂的运动学模型，建立基座姿态与机械臂工作空间的可达性之间的映射关系，
并据此设计了物理可行性引导（Physical Feasibility Guidance, 简称PFG）奖励机制。
该机制通过实时判断当前躯干姿态是否能让机械臂在关节配置安全域内达到目标位姿，
从而有效约束并引导策略探索方向，最终实现了足式机械臂流畅、鲁棒的全身运动与操作协同。

\section{问题与挑战}
由于足式机械臂在物流、巡检、赈灾救援等领域展现出巨大的应用潜力，其复杂性对机器人的
控制与部署系统提出了更高的要求。基于前文对该系统特性和现有方法局限性的分析，
本文的主要研究内容聚焦于解决以下关键问题与挑战：

\textbf{足式机械臂全身协同控制：}由于MPC方法需要复杂的建模建模步骤、高昂
的计算开销，并且难以实现身体与手臂之间的自然流畅配合，这推动了研究向数据驱动的深度强化学习转型。
尽管DRL优势显著，但应用于足式机械臂的全身控制仍面临一些严峻的挑战：
\begin{itemize}
      \item 多目标耦合与次优收敛： 足式机械臂的全身控制涉及基座稳定运动和
            机械臂精确操作这两个强耦合的任务目标。DRL策略的优化依赖于奖励函数
            对两个目标的加权评估。然而，由于奖励函数的权衡设计难度极高，DRL算法难以在优化过程
            中有效平衡相互制约的任务。这导致训练出的策略容易过度倾向于某一特定任务，
            最终收敛到次优或局部最优解，严重影响了控制器最终性能。
      \item 探索效率与行为流畅性缺失： 现有的DRL协同控制方法在处理高维连续动作空间
            时，通常缺乏对系统物理可行性的先验指导，导致策略探索效率低下。已有的解耦训练
            或优势混合方法往往采用两阶段训练，训练耗时，且难以得到高度自然、流畅且具备
            高鲁棒性的全身协同行为，制约了策略的实用性。
      \item 高精度追踪的难以实现： 相比于MPC等基于模型的优化方法，DRL策略
            由于其固有的函数逼近误差和随机探索特性，在实现高精度、高收敛性的末端执行器
            位姿追踪任务时往往表现不佳。这种相对较低的追踪精确度，对于需要精细触碰、抓取
            或插入等操作任务的机械臂而言，是阻碍足式机械臂广泛应用的重要障碍。
\end{itemize}

\textbf{足式机械臂异构系统的Sim2Real部署鸿沟：}
足式机械臂系统本质上是一个异构系统：它将四足机器人与机械臂集成在一起。
这种异构性导致Sim2Real（仿真到现实）部署鸿沟被进一步放大。
\begin{itemize}
      \item 驱动器特性差异： 四足机器人通常采用大扭矩、低减速比的行星减速器电机，
            强调动态响应和功率密度；而机械臂则普遍采用高减速比、
            高精度的谐波减速器电机，强调刚度和高精度定位。
            这种显著的硬件差异导致其电机控制特性在仿真中难以被统一和精确建模。
      \item 高增益控制的仿真难度： 机械臂为了保证操作精度，需要使用较大
            的$K_p$和$K_d$增益进行控制。在仿真环境中，使用如此大的控制增益
            来精确模拟机械臂的电机控制特性极具挑战性，细微的建模误差在高增益下
            会被放大，导致在仿真中训练过程难以收敛，策略输出趋向于振荡，极大地制约
            了强化学习策略的实际部署。
\end{itemize}

\textbf{全身控制系统的故障容错与鲁棒性架构设计：}
在现实世界的任务执行中，故障障容错能力和系统鲁棒性是足式机械臂从实验室走向实
际应用的关键指标。足式机械臂的复杂性要求其能够在执行操作时，有效地应对子系统（机械臂）
的突发性故障，避免控制系统崩溃。
\begin{itemize}
      \item 功能解耦与故障隔离挑战： 尽管足式机械臂的控制目标是高度耦合的，
            但其控制主体（基座与机械臂）在控制逻辑上应实现故障隔离。
            具体而言，当机械臂因电机过热或传感器故障等问题
            导致控制失效时，控制系统不应因该子系统的故障而崩溃，
            而是需要迅速克服机械臂失控带来的扰动，保持基座的稳定运动控制，
            从而将故障机械臂安全地转移到收纳或维修位姿。
      \item 鲁棒性架构与先验知识的局限： 基于模型的传统方法（如MPC）
            通常将足式机械臂视为一个单一体、完全耦合的系统进行优化，其控制律依赖
            于模型的假设，本质上缺乏对子系统故障的内在感知和应对机制。
            虽然深度强化学习（DRL）作为一种数据驱动的方法，
            有可能通过在仿真中注入故障数据来学习相应的故障容错策略和解耦状态，
            但如何高效、系统性地构建并验证这种具备故障容错能力的DRL架构，
            仍是一个问题。
\end{itemize}

\textbf{非结构化环境中的动态全身控制与感知融合：}
足式机械臂的最终应用场景是户外、灾区或家庭等典型的非结构化环境。在这些场景中，足式机械臂不仅要克服
复杂、动态变化的崎岖地形如碎石、泥泞、楼梯，还必须使用机械臂在移动过程中进行相应操作任务。
\begin{itemize}
      \item 高动态全身协同控制的实时性与鲁棒性：在复杂地形上保持稳定移动本身就是一项
            高动态控制难题。当系统同时执行全身协同操作时，需要在极高频率的运动控制环中实时
            融合环境感知、本体状态和操作目标信息。实现基座动态稳定与机械臂操作一体化的控制系统，
            对算法的提出了极高的要求。
      \item 感知不确定性与地形适应性挑战：非结构化环境中的传感器数据不可避免地存在
            噪声、漂移和遮挡（即感知不确定性）。足式机械臂需要智能地在依赖感知的模式
            与不依赖感知的盲走模式之间进行鲁棒切换，以适应环境变化。此外，为了在复杂
            地形上扩展机械臂的工作空间或保持身体稳定，系统必须具备强大的全身协同能力，
            以在满足操作约束的同时，确保足端与地面的物理可行性接触，
            并利用机械臂完成相应操作任务。
\end{itemize}

\section{本文研究内容与贡献}

基于上述全身控制器面临的关键挑战，本文围绕基于强化学习的足式机械臂全身协同运动
控制方法、异构系统sim2real方法、物理可行域引导的奖励设计方法、与基于空间注意
力的感知融合方法展开研究。

在足式机械臂的全身控制架构方法，我们采用了PPO强化学习算法，使用了非对称性Actor-Critic架构。
在训练过程中，Actor与Critic网络接受的输入完全不一样。Critic没有任何的部署的需求，因此接受
理想无噪声的机器人状态数据，这些状态数据可以直接从仿真中获取。这种方法使得Critic估计的Value
值更加准确，从而高效的指导策略收敛。而Actor网络（即策略网络）的输入则严格受限于在真实机器人上
可获取的信息，这确保了策略的直接可部署性。实验证明采用非对称性的网络结构设计能够加速收敛，提升
训练效率与最终策略的效果。

在此基础上，为了弥补足式机械臂控制系统在仿真域现实之间的巨大鸿沟，我们采用了分离式框架设计，
结合域随机化与课程设计方法，通过对各个传感器收集的数据加入噪声和延迟，来模拟真实机器人上的
传感器数据。例如：对于机器人控制器，我们采用了双延迟缓冲器的设计来模拟控制延迟。对于机器人关节
状态数据，我们通过单延迟缓冲器与引入高斯噪声来模拟真实机器人上获得的关节状态数据。
对于地形感知数据，我们模仿elevation mapping地图更新方法，
通过内部维护部分一个局部地图，来模拟在真实机器人上获得的地形感知数据。
除此之外，机械臂与四足机器人采用的电机不同，相比四足机器人的电机，机械臂采用了谐波减速器，需要极大的
$K_p$与$K_d$增益来实现高精度的控制。在仿真训练中，策略网络的微小输出被极大的$K_p$与$K_d$
放大，导致机械臂运动振荡，这使得训练的策略难以部署在真实的机器人上。为了解决这个问题，
我们引入了虚拟力奖励引导机制，力矩奖励并非由机械臂真实的控制力矩生成，而是由一个理想pd控制器生成，
尽管该力矩并不是真正的作用在机械臂上。但是在优化过程中，这个奖励可以让策略网络学习
到PD控制器位置与力的关系，进而改变输出幅值，减轻振荡效应。

操作与移动的全身协同控制问题是足式机械臂控制中的关键难点。
在学习过程中，策略往往难以学习身体与手臂的配合行为，原因是，身体的配合会对四足机器人
的速度追踪任务产生负面影响，为了获得更好的速度追踪性能，策略往往会忽略身体的配合行为，
此时策略逐渐收敛至局部最优。
针对现有DRL方法在平衡“稳定移动”和“精确操作”两大耦合目标时容易收敛至局部最优的局限。
本文提出了基于物理可行域引导的奖励设计方法。该方法借鉴生物体在移动中进行操作的
协同原理，将显式的机器人运动学模型作为先验知识引入奖励函数。
在训练过程中，当身体状态使得操作任务可达时，该身体状态被是视为一个可行身体状态。
策略不仅仅追求任务奖励的最大化，还需要探索并保留在给定操作任务下的可行
身体状态。该方法能有效的引导了策略探索方向，使得策略收敛避开局部最优解，最终实现了足式
机械臂流畅、鲁棒的全身运动与操作协同。

此外，足式机械臂在非结构化场景中面临的传感器不确定性和故障容错挑战，我们设计了一种基于
空间注意力机制的网络模型，以实现机器人内部状态与环境感知的鲁棒融合。该模型利用空间注意
力机制动态调整网络对环境感知信息的权重，并结合门控神经网络结构，实现了对感知信息的鲁棒
处理。当外部感知数据因噪声或故障而不可用时，网络能够智能地退化为基于内部状态的无感知模式。
这种动态的鲁棒切换能力，有效增强了全身控制器的环境适应性与故障容错能力，确保了足式机械臂
在复杂地形上执行操作任务的可靠性。

\section{本文结构}
本文共有六章，结构安排如下：

第一章主要介绍了足式机械臂系统的发展背景与研究意义，明确指出了当前足式机械臂全身协同控制领域
面临的技术挑战，并概述了本文的研究动机、主要内容与核心贡献。


\chapter{足式机械臂全身控制方法概述}

\chapter{基于强化学习的足式机械臂全身运动控制}

\chapter{异构系统sim2real方法}

\chapter{感知融合物理可行域奖励设计方法}


% \chapter{关于本模板}

% 本模板根据浙江大学研究生院编写的《浙江大学研究生学位论文编写规则》~\cite{zjugradthesisrules}，
% 在原有的 zjuthesis 模板~\cite{zjuthesis}基础上开发而来。

% 本模板的本科生版本\cite{zjuthesisrules}得到了浙江大学本科生院老师的支持与审核，
% 已经在本科生院网上公示。
% 但当前的研究生版本并未经过研究生院老师的审核，
% 同学们使用时要注意对照模板与要求，
% 切不可盲目使用。

% 作者本人并未编写过浙江大学研究生毕业论文，
% 所以不清楚具体要求。
% 如果有热心同学愿意帮忙，
% 可以替我联系相关老师，我会配合审核并修改代码。

% \section{Overleaf 使用注意事项}

% 如果你在Overleaf上编译本模板，请注意如下事项：

% \begin{itemize}
%     \item 删除根目录的 ``.latexmkrc'' 文件，否则编译失败且不报任何错误
%     \item 字体有版权所以本模板不能附带字体，请务必手动上传字体文件，并在各个专业模板下手动指定字体。
%           具体方法参照 GitHub 主页的说明。
%     \item 当前的Overleaf默认使用TexLive 2017进行编译，但一些伪粗体复制乱码的问题需要TexLive 2019版本来解决。
%           所以各位同学可以在Overleaf上编写论文时务必切换到TexLive 2019或更新版本来编译，以免产生查重相关问题。
%           具体说明参照 GitHub 主页。
% \end{itemize}


% \section{节标题}

% 我们可以用includegraphics来插入现有的jpg等格式的图片，
% 如\autoref{fig:zju-logo}所示。

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.3\linewidth]{logo/zju}
%     \caption{\label{fig:zju-logo}浙江大学LOGO}
% \end{figure}


% \subsection{小节标题}


% \par 如\autoref{tab:sample}所示，这是一张自动调节列宽的表格。

% \begin{table}[htbp]
%     \caption{\label{tab:sample}自动调节列宽的表格}
%     \begin{tabularx}{\linewidth}{c|X<{\centering}}
%         \hline
%         第一列 & 第二列 \\ \hline
%         xxx & xxx \\ \hline
%         xxx & xxx \\ \hline
%         xxx & xxx \\ \hline
%     \end{tabularx}
% \end{table}


% \par 如\autoref{equ:sample}，这是一个公式

% \begin{equation}
%     \label{equ:sample}
%     A=\overbrace{(a+b+c)+\underbrace{i(d+e+f)}_{\text{虚数}}}^{\text{复数}}
% \end{equation}

% \chapter{另一章}


% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.3\linewidth]{example-image-a}
%     \caption{\label{fig:fig-placeholder}图片占位符}
% \end{figure}

% \chapter{再一章}

% \par 如\autoref{alg:sample}，这是一个算法

% \begin{algorithm}[H]
%     \begin{algorithmic} % enter the algorithmic environment
%         \REQUIRE $n \geq 0 \vee x \neq 0$
%         \ENSURE $y = x^n$
%         \STATE $y \Leftarrow 1$
%         \IF{$n < 0$}
%         \STATE $X \Leftarrow 1 / x$
%         \STATE $N \Leftarrow -n$
%         \ELSE
%         \STATE $X \Leftarrow x$
%         \STATE $N \Leftarrow n$
%         \ENDIF
%         \WHILE{$N \neq 0$}
%         \IF{$N$ is even}
%         \STATE $X \Leftarrow X \times X$
%         \STATE $N \Leftarrow N / 2$
%         \ELSE[$N$ is odd]
%         \STATE $y \Leftarrow y \times X$
%         \STATE $N \Leftarrow N - 1$
%         \ENDIF
%         \ENDWHILE
%     \end{algorithmic}
%     \caption{\label{alg:sample}算法样例}
% \end{algorithm}
